# å†³ç­–å¾ªç¯ (Decision Loop)

> æœ¬æ–‡æ¡£ä»‹ç» Maicraft-Next çš„å†³ç­–å¾ªç¯æœºåˆ¶

---

## ğŸ¯ ä¸¤ç§å†³ç­–å¾ªç¯

### MainDecisionLoop - ä¸»å†³ç­–å¾ªç¯

è´Ÿè´£ Agent çš„ä¸»è¦è‡ªä¸»å†³ç­–å’Œè¡ŒåŠ¨ã€‚

**å·¥ä½œæµç¨‹**ï¼š

1. æ”¶é›†å½“å‰çŠ¶æ€å’Œä¸Šä¸‹æ–‡
2. ç”Ÿæˆå†³ç­– Prompt
3. è°ƒç”¨ LLM è·å–å†³ç­–
4. è§£æå¹¶æ‰§è¡ŒåŠ¨ä½œ
5. è®°å½•å†³ç­–å’Œç»“æœ
6. ç­‰å¾…ä¸‹ä¸€æ¬¡å¾ªç¯

### ChatLoop - èŠå¤©å¾ªç¯

å¤„ç†ä¸ç©å®¶çš„èŠå¤©äº’åŠ¨ã€‚

**è§¦å‘æ–¹å¼**ï¼š

- ç©å®¶å‘é€èŠå¤©æ¶ˆæ¯
- æ¶ˆæ¯åŒ…å«ç‰¹å®šå‰ç¼€ï¼ˆå¦‚ `@bot`ï¼‰

---

## ğŸ’» åŸºæœ¬æµç¨‹

### MainDecisionLoop

```typescript
export class MainDecisionLoop {
  async run(): Promise<void> {
    while (this.state.isRunning) {
      // 1. æ£€æŸ¥ä¸­æ–­
      if (this.state.interrupt.isInterrupted()) {
        await this.handleInterrupt();
      }

      // 2. æ›´æ–°ä»»åŠ¡è¿›åº¦
      await this.state.planningManager.updateProgress();

      // 3. ç”Ÿæˆ Prompt
      const prompt = await this.generatePrompt();

      // 4. è°ƒç”¨ LLM
      const response = await this.llmManager.chat(prompt);

      // 5. è®°å½•æ€ç»´
      await this.state.memory.thought.record({
        category: 'decision',
        content: response.thinking,
      });

      // 6. æ‰§è¡ŒåŠ¨ä½œ
      const result = await this.executeAction(response.action, response.params);

      // 7. è®°å½•å†³ç­–
      await this.state.memory.decision.record({
        action: response.action,
        params: response.params,
        result,
        reasoning: response.thinking,
      });

      // 8. ç­‰å¾…
      await this.sleep(this.config.decision_interval || 5000);
    }
  }
}
```

### ChatLoop

```typescript
export class ChatLoop {
  async handleMessage(username: string, message: string): Promise<void> {
    // 1. è®°å½•å¯¹è¯
    await this.state.memory.conversation.record({
      speaker: username,
      message,
    });

    // 2. ç”Ÿæˆå›å¤ Prompt
    const prompt = this.promptManager.generateChatResponse(this.state.context, {
      username,
      message,
      conversationHistory: await this.state.memory.conversation.query({ limit: 10 }),
    });

    // 3. è°ƒç”¨ LLM
    const response = await this.llmManager.chat(prompt);

    // 4. å‘é€å›å¤
    await this.state.context.executor.execute(ActionIds.CHAT, {
      message: response.content,
    });

    // 5. è®°å½•å›å¤
    await this.state.memory.conversation.record({
      speaker: this.state.context.bot.username,
      message: response.content,
      response_to: username,
    });
  }
}
```

---

## ğŸ”§ é…ç½®é€‰é¡¹

```toml
[agent]
decision_interval = 5000  # å†³ç­–é—´éš”ï¼ˆæ¯«ç§’ï¼‰
chat_enabled = true       # æ˜¯å¦å¯ç”¨èŠå¤©å¾ªç¯
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä»£ç†ç³»ç»Ÿ](agent-system.md)
- [LLM é›†æˆ](llm-integration.md)
- [æç¤ºè¯ç³»ç»Ÿ](prompt-system.md)

---

_æœ€åæ›´æ–°: 2025-11-01_
